{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Grupos5-EDA-icesi/Analisis-Exploratorio/blob/Camila-Diaz/Final_analisis_modelo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbl2e-3e7RKA"
      },
      "source": [
        "# **Grupo 5**\n",
        "\n",
        "### Juan Carlos Zuñiga M, Julián Morales, Leonardo Agudelo y Maria Camila Diaz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3Dv6QNDI7RKC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd                 #libreria para manejo de datos\n",
        "import numpy as np                  #libreria para manejo de datos\n",
        "\n",
        "import matplotlib.pyplot as plt     #libreria para graficos\n",
        "import seaborn as sns               #libreria para graficos\n",
        "\n",
        "import statsmodels.api as sm        #libreria para modelos estadisticos\n",
        "from sklearn.metrics import mean_squared_error  #libreria para metricas de error\n",
        "\n",
        "import random                 #mean_squared_error(y_true, y_pred) es la media del cuadrado de los errores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oREcL90v7RKE"
      },
      "source": [
        "## Descripcion:\n",
        "\n",
        "La organización necesita predecir qué tipo de planes de internet y en qué rango de precios serán más contratados en los próximos 3 meses, considerando el impacto del estrato socioeconómico en la decisión de compra.\n",
        "\n",
        "Actualmente, no existe un modelo predictivo que permita anticipar la demanda según el precio y el estrato, lo que podría generar una oferta desalineada con las necesidades del mercado, afectando la rentabilidad, planificación comercial y fidelización de clientes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8h7Lu7e7RKE"
      },
      "source": [
        "# PREGUNTA SMART\n",
        "\n",
        "## **¿Qué tipo de planes de internet y en qué rango de precios tienen mayor probabilidad de ser contratados en los próximos 3 meses, segmentados por estrato socioeconómico, con base en el histórico de ventas, rechazos y características de clientes en Cali?**\n",
        "\n",
        "\n",
        "* **Específica**:   Define los tipo de planes, en Cali, segmentado por estrato, y con histórico de ventas, rechazados y características.\n",
        "\n",
        "* **Medible**:\tSe puede medir con frecuencias, ordendes creadas/rechazo, tendencias históricas y modelos predictivos.\n",
        "\n",
        "* **Alcanzable**:\tcuenta con un histórico de datos sobre ventas, rechazos y características de los clientes, lo que permite aplicar técnicas de análisis exploratorio y modelos predictivos. Con herramientas como Python, pandas y scikit-learn facilitan el procesamiento de la información y la construcción de modelos de predicción para estimar la probabilidad de contratación de cada tipo de plan.\n",
        "\n",
        "* **Relevante**:\tPermite tomar decisiones estratégicas: diseñar planes por segmento, ajustar campañas y anticipar demanda.\n",
        "\n",
        "* **Temporal**:\tDefine un horizonte de análisis a \"los próximos meses\", lo que permite actualizaciones periódicas y adaptación al mercado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvIGxECM7RKF"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoRuA7FK7RKG"
      },
      "source": [
        "#  Analisis Exploratorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Cm7mqD8x7RKH",
        "outputId": "76f150c0-dc37-4cbf-b44f-3a6a369177fc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './Data/data_balanceada.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ab89a2d977ef>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Data/data_balanceada.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#df = pd.read_csv('https://github.com/Grupos5-EDA-icesi/Analisis-Exploratorio/raw/main/FINAL/Data/data_sin_nulos.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Mostrar las dimensiones del DataFrame (filas, columnas)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Data/data_balanceada.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"./Data/data_balanceada.csv\")\n",
        "#df = pd.read_csv('https://github.com/Grupos5-EDA-icesi/Analisis-Exploratorio/raw/main/FINAL/Data/data_sin_nulos.csv')\n",
        "\n",
        "# Mostrar las dimensiones del DataFrame (filas, columnas)\n",
        "print(df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnh91FTJ7RKJ"
      },
      "source": [
        "# EDA - Analisis Exploratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJCZYN3p7RKK"
      },
      "source": [
        "## Analisis de Estructura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "nJESgyQf7RKK",
        "outputId": "f29178c6-4df1-4e50-eb4d-38e23b013068"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5292fd02e247>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mostrar el nuevo DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "# Mostrar el nuevo DataFrame\n",
        "df.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3a4SdqG7RKL"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8TNzw537RKM"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()     # Contar los valores nulos por columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-9qoIHk7RKM"
      },
      "outputs": [],
      "source": [
        "# Seleccionar las columnas categóricas\n",
        "categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# Mostrar el número de columnas categóricas\n",
        "print(f\"Número de variables categóricas: {len(categorical_columns)}\")\n",
        "\n",
        "# Mostrar los nombres de las columnas categóricas\n",
        "print(\"Variables categóricas:\")\n",
        "print(categorical_columns.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv7itVXK7RKM"
      },
      "outputs": [],
      "source": [
        "# Seleccionar variables categóricas a analizar\n",
        "categorical_vars = ['Genero', 'nombre_zone', 'motivo_rechazo_solicitud', 'grupo_edad', 'tipo_plan', 'venta']\n",
        "\n",
        "# Configurar el tamaño del gráfico\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Crear gráficos de barras para cada variable categórica\n",
        "for i, var in enumerate(categorical_vars, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    df[var].value_counts().sort_index().plot(kind='bar', color=['blue', 'orange', 'green', 'red', 'purple'])\n",
        "    plt.title(f'Distribución de {var}')\n",
        "    plt.xlabel(var)\n",
        "    plt.ylabel('Cantidad de Clientes')\n",
        "    plt.xticks(rotation=90, ha='center')  # Rotar etiquetas del eje x a 90 grados y centrar\n",
        "\n",
        "# Ajustar diseño\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2gxgdzz7RKN"
      },
      "outputs": [],
      "source": [
        "# Seleccionar las columnas numéricas\n",
        "numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Mostrar el número de columnas numéricas\n",
        "print(f\"Número de variables numéricas: {len(numeric_columns)}\")\n",
        "\n",
        "# Mostrar los nombres de las columnas numéricas\n",
        "print(\"Variables numéricas:\")\n",
        "print(numeric_columns.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZzXfY7Q7RKN"
      },
      "outputs": [],
      "source": [
        "# Seleccionar solo las variables numéricas\n",
        "df_numeric = df.select_dtypes(include=[np.number])\n",
        "\n",
        "# Calcular la matriz de correlación\n",
        "corr_matrix = df_numeric.corr()\n",
        "\n",
        "# Crear un mapa de calor de correlaciones\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
        "plt.title(\"Mapa de Calor de Correlaciones entre Variables Numéricas\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teTKPSVj7RKN"
      },
      "source": [
        "- No hay correlaciones fuertes con la variable venta\n",
        "\n",
        "- La columna venta muestra correlaciones muy bajas con todas las demás variables.\n",
        "\n",
        "- El mayor valor es 0.10 con plan_MB, lo que sugiere que la cantidad de megas del plan tiene una leve influencia en la decisión de compra, pero es muy débil.Esto indica que la variable venta no depende fuertemente de ninguna variable numérica presente en este análisis.\n",
        "\n",
        "- price_plan y plan_MB tienen una correlación moderada (0.44), ya que los planes con más megas suelen tener un precio más alto. Esto sugiere que el precio y la capacidad del plan están relacionados, lo cual es esperable.\n",
        "\n",
        "- El estrato tiene una correlación positiva con price_plan (0.37) Puede significar que a mayor estrato socioeconómico, mayor es el precio del plan contratado. Esto indica que el nivel socioeconómico influye en la elección del plan.\n",
        "\n",
        "- No hay relaciones relevantes con Edad\n",
        "\n",
        "- La Edad tiene correlaciones muy bajas con todas las variables, indicando que no es un factor determinante en este análisis.\n",
        "\n",
        "- El mes (mes) tiene una correlación débil con plan_MB (0.39)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiroUwie7RKO"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df_numeric, height=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydtg4g8S7RKO"
      },
      "source": [
        "## Variable price_plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_5W6iAE7RKO"
      },
      "outputs": [],
      "source": [
        "#descripcion de la variable price_plan\n",
        "df[\"price_plan\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gP8ydktk7RKO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df['price_plan'], bins=15, kde=True, color='blue', alpha=0.6)\n",
        "plt.xlabel('Precio del Plan')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('Distribución de Precios de los Planes')\n",
        "\n",
        "# Línea de la mediana para destacar la asimetría\n",
        "plt.axvline(df['price_plan'].median(), color='red', linestyle='dashed', label='Mediana')\n",
        "plt.legend()\n",
        "\n",
        "# Mostrar gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a84O_K1z7RKP"
      },
      "outputs": [],
      "source": [
        "# Definir los rangos de precio\n",
        "bins_precio = [0, 60000, 70000, 80000, 90000, 100000, float('inf')]\n",
        "labels_precio = ['< 60k', '60k - 70k', '70k - 80k', '80k - 90k', '90k - 100k', '> 100k']\n",
        "\n",
        "# Crear una nueva columna con los grupos de precio\n",
        "#df['grupo_precio'] = pd.cut(df['price_plan'], bins=bins_precio, labels=labels_precio, right=False)\n",
        "\n",
        "# Variables categóricas a analizar\n",
        "categorical_vars = ['estrato', 'nombre_zone']\n",
        "\n",
        "# Crear la figura y los ejes para las subgráficas\n",
        "fig, axes = plt.subplots(2, 1, figsize=(8, 10))\n",
        "\n",
        "# Crear gráficos de barras apilados para cada variable categórica\n",
        "for i, var in enumerate(categorical_vars):\n",
        "    # Crear los grupos de precio temporalmente\n",
        "    grupo_precio = pd.cut(df['price_plan'], bins=bins_precio, labels=labels_precio, right=False)\n",
        "\n",
        "    # Crear la tabla de contingencia\n",
        "    tabla_contingencia = pd.crosstab(df[var], grupo_precio)\n",
        "\n",
        "    # Crear el gráfico de barras apilado\n",
        "    tabla_contingencia.plot(kind='bar', stacked=True, ax=axes[i], colormap='viridis')\n",
        "    axes[i].set_xlabel(var)\n",
        "    axes[i].set_ylabel('Cantidad de Contrataciones')\n",
        "    axes[i].set_title(f'Distribución de Planes por {var.capitalize()} y Grupo de Precio')\n",
        "    axes[i].legend(title=\"Grupo de Precio\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=0)\n",
        "\n",
        "# Ajustar diseño\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "573TOBn37RKP"
      },
      "outputs": [],
      "source": [
        "# Configuración de estilo\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Obtener el número de categorías en plan_MB\n",
        "num_categories = df['plan_MB'].nunique()\n",
        "\n",
        "# Definir una paleta de colores personalizada con el número exacto de categorías\n",
        "custom_palette = sns.color_palette(\"bright\", num_categories)\n",
        "\n",
        "# Gráfico de relación entre precio del plan por mes y por plan_MB\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=df, x=\"mes\", y=\"price_plan\", hue=\"plan_MB\", marker=\"o\", palette=custom_palette)\n",
        "plt.title(\"Relación de Precio del Plan por Mes y por plan_MB\")\n",
        "plt.xlabel(\"Mes\")\n",
        "plt.ylabel(\"Precio del Plan\")\n",
        "plt.legend(title=\"plan_MB\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUV3afqf7RKP"
      },
      "source": [
        "## Variable estrato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btQFNauE7RKP"
      },
      "outputs": [],
      "source": [
        "# Análisis de distribución del precio en ventas exitosas vs. rechazadas\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(data=df, x=\"estrato\", y=\"price_plan\", hue=\"venta\", palette=\"Set2\")\n",
        "plt.title(\"Distribución del Precio en Ventas Exitosas vs. Rechazadas por Estrato\")\n",
        "plt.xlabel(\"Estrato Socioeconómico\")\n",
        "plt.ylabel(\"Precio del Plan\")\n",
        "plt.legend(title=\"Venta (1=Sí, 0=No)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgl_UHBh7RKQ"
      },
      "source": [
        "### Distribución del Precio en Ventas Exitosas vs. Rechazadas por Estrato:\n",
        "\n",
        "- Se observa la dispersión de los precios de los planes contratados y rechazados en cada estrato socioeconómico.\n",
        "- Se pueden identificar rangos de precios más aceptados y aquellos que tienden a ser rechazados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcboOyQ57RKQ"
      },
      "outputs": [],
      "source": [
        "# Frecuencia de contratación por tipo de plan y estrato\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(data=df[df[\"venta\"] == 1], x=\"estrato\", hue=\"tipo_plan\", palette=\"Set2\")\n",
        "plt.title(\"Frecuencia de Contratación por Tipo de Plan y Estrato\")\n",
        "plt.xlabel(\"Estrato Socioeconómico\")\n",
        "plt.ylabel(\"Número de Contrataciones\")\n",
        "plt.legend(title=\"Tipo de Plan\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K3fsBoS7RKQ"
      },
      "outputs": [],
      "source": [
        "# Evolución de las ventas por tipo de plan a lo largo del tiempo\n",
        "df_ventas = df[df[\"venta\"] == 1].groupby([\"mes\", \"tipo_plan\"]).size().reset_index(name=\"total_ventas\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=df_ventas, x=\"mes\", y=\"total_ventas\", hue=\"tipo_plan\", marker=\"o\")\n",
        "plt.title(\"Evolución de Ventas por Tipo de Plan\")\n",
        "plt.xlabel(\"Mes\")\n",
        "plt.ylabel(\"Número de Ventas\")\n",
        "plt.legend(title=\"Tipo de Plan\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4DNk73C7RKQ"
      },
      "source": [
        "### Frecuencia de Contratación por Tipo de Plan y Estrato:\n",
        "\n",
        "- Se muestra cuántos planes han sido contratados en cada estrato, diferenciados por tipo de plan.\n",
        "- Esto permite identificar qué tipos de planes son más populares en cada nivel socioeconómico.\n",
        "\n",
        "### Evolución de Ventas por Tipo de Plan:\n",
        "\n",
        "- Se observa cómo han variado las ventas de los diferentes tipos de planes a lo largo de los meses.\n",
        "- Es útil para detectar tendencias crecientes o decrecientes en la demanda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmUzbFqW7RKQ"
      },
      "source": [
        "## Solicitudes rechazadas por estrato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPEswaN17RKQ"
      },
      "outputs": [],
      "source": [
        "# Filtrar solo los casos donde la venta fue rechazada (retiros o no contratación)\n",
        "df_retiros = df[df[\"venta\"] == 0]\n",
        "\n",
        "# Contar la cantidad de rechazos por estrato\n",
        "retiros_por_estrato = df_retiros[\"estrato\"].value_counts().sort_index()\n",
        "\n",
        "# Crear el gráfico de barras\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=retiros_por_estrato.index, y=retiros_por_estrato.values, hue=retiros_por_estrato.index, palette=\"muted\", dodge=False, legend=False)\n",
        "plt.title(\"Cantidad de Solicitudes Rechazadas por Estrato\")\n",
        "plt.xlabel(\"Estrato Socioeconómico\")\n",
        "plt.ylabel(\"Cantidad de Rechazos\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoKck4Ge7RKQ"
      },
      "outputs": [],
      "source": [
        "# Motivos de rechazo predominantes por estrato\n",
        "df_motivos = df[df[\"venta\"] == 0].groupby([\"estrato\", \"motivo_rechazo_solicitud\"]).size().reset_index(name=\"total_rechazos\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=df_motivos, x=\"estrato\", y=\"total_rechazos\", hue=\"motivo_rechazo_solicitud\", palette=\"Set3\")\n",
        "plt.title(\"Motivos de Rechazo Predominantes por Estrato\")\n",
        "plt.xlabel(\"Estrato Socioeconómico\")\n",
        "plt.ylabel(\"Cantidad de Rechazos\")\n",
        "plt.legend(title=\"Motivo de Rechazo\", bbox_to_anchor=(1, 1))\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWxfr8XP7RKR"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Selección de variables relevantes para el clustering\n",
        "variables_clustering = [\"Edad\", \"estrato\", \"price_plan\", \"plan_MB\"]\n",
        "df_cluster = df[df[\"venta\"] == 1][variables_clustering].dropna()\n",
        "\n",
        "# Escalado de las variables para mejor desempeño del clustering\n",
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(df_cluster)\n",
        "\n",
        "# Determinación del número óptimo de clusters con el método del codo\n",
        "inertia = []\n",
        "for k in range(1, 10):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(df_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Gráfico del método del codo\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, 10), inertia, marker=\"o\", linestyle=\"--\")\n",
        "plt.xlabel(\"Número de Clusters\")\n",
        "plt.ylabel(\"Inercia\")\n",
        "plt.title(\"Método del Codo para Determinar el Número de Clusters\")\n",
        "plt.show()\n",
        "\n",
        "# Aplicación de K-Means con el número óptimo de clusters (probablemente 3 o 4)\n",
        "optimal_k = 4  # Se puede ajustar tras revisar el gráfico del codo\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "df_cluster[\"cluster\"] = kmeans.fit_predict(df_scaled)\n",
        "\n",
        "# Perfil de los clusters (promedio de cada variable por cluster)\n",
        "df_cluster.groupby(\"cluster\").mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUQhpmHf7RKR"
      },
      "source": [
        "## Interpretación de los clusters:\n",
        "\n",
        "- Cluster 0: Clientes mayores (~53 años), estrato bajo, contratan planes de 266 MB a precios medios.\n",
        "- Cluster 1: Clientes jóvenes (~29 años), estrato bajo, eligen planes similares en precio y velocidad (274 MB).\n",
        "- Cluster 2: Clientes de estratos altos (4.19), con los planes más costosos (~$75,900) y de alta velocidad (274 MB).\n",
        "- Cluster 3: Clientes de edad media (~41 años), pero con planes de menor velocidad (100 MB)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qcwe_wQw7RKR"
      },
      "source": [
        "## Codificacion de variables categóricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBXMk6qT7RKR"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zd6lmy0H7RKR"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh3bc6257RKR"
      },
      "outputs": [],
      "source": [
        "# Seleccionar las columnas categóricas\n",
        "categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# Mostrar el número de columnas categóricas\n",
        "print(f\"Número de variables categóricas: {len(categorical_columns)}\")\n",
        "\n",
        "# Mostrar los nombres de las columnas categóricas y la cantidad de categorías en cada una\n",
        "print(\"Cantidad de categorías por variable categórica:\")\n",
        "for col in categorical_columns:\n",
        "    num_categories = df[col].nunique()\n",
        "    print(f\"{col}: {num_categories} categorías\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NRNb_oP7RKS"
      },
      "source": [
        "### transformación de columna label encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxDiDhGP7RKS"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "\n",
        "\n",
        "df['genero_label'] = labelencoder.fit_transform(df['Genero'])\n",
        "\n",
        "df['tipo_plan_label'] = labelencoder.fit_transform(df['tipo_plan'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCqG1wJO7RKS"
      },
      "outputs": [],
      "source": [
        "#eliminar columnas originales\n",
        "df = df.drop(['Genero', 'tipo_plan'], axis=1)\n",
        "# Mostrar el DataFrame después de eliminar las columnas\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWs8JCjk7RKS"
      },
      "source": [
        "### transformación de columna one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im8Z1aQc7RKT"
      },
      "outputs": [],
      "source": [
        "# Supongamos que tienes las siguientes columnas categóricas nominales\n",
        "categorical_columns = ['nombre_zone', 'grupo_edad']\n",
        "\n",
        "# Aplicar One-Hot Encoding\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Ver el resultado\n",
        "df_encoded.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TfnZLUC7RKT"
      },
      "outputs": [],
      "source": [
        "df_encoded.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prgdrcoq7RKU"
      },
      "outputs": [],
      "source": [
        "# Supongamos que tienes las siguientes columnas categóricas nominales\n",
        "\n",
        "# Aplicar One-Hot Encoding\n",
        "df_encoded = pd.get_dummies(df_encoded, columns=['motivo_rechazo_solicitud'])\n",
        "\n",
        "# Ver el resultado\n",
        "df_encoded.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzKtdFOy7RKU"
      },
      "outputs": [],
      "source": [
        "df_encoded.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgxs0Gmx7RKU"
      },
      "outputs": [],
      "source": [
        "# Guardar el DataFrame en un archivo CSV\n",
        "df_encoded.to_csv(\"./Data/data_codificada.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XxGRjDG7RKU"
      },
      "source": [
        "***\n",
        "***\n",
        "***\n",
        "***\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWBTe5I67RKV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewl29m-M7RKV"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./Data/data_codificada.csv\")\n",
        "#df = pd.read_csv('https://github.com/Grupos5-EDA-icesi/Analisis-Exploratorio/raw/main/FINAL/Data/data_sin_nulos.csv')\n",
        "\n",
        "# Mostrar las dimensiones del DataFrame (filas, columnas)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amjuzd5p7RKV"
      },
      "outputs": [],
      "source": [
        "#Identificar Valores Duplicados\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZEn92Ho7RKV"
      },
      "outputs": [],
      "source": [
        "# Eliminar duplicados y mantener solo la primera aparición\n",
        "df = df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIDl4KJh7RKV"
      },
      "outputs": [],
      "source": [
        "# Calcular la matriz de correlación\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Visualizar la matriz de correlación\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Matriz de Correlación\")\n",
        "plt.show()\n",
        "\n",
        "# Seleccionar características con alta correlación con la variable objetivo\n",
        "target_correlation = correlation_matrix['venta'].abs().sort_values(ascending=False)\n",
        "print(target_correlation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-VvEsn67RKV"
      },
      "outputs": [],
      "source": [
        "#eliminar la variable motivo_rechazo_solicitud_No Aplica\n",
        "\n",
        "# df = df.drop(['motivo_rechazo_solicitud_No Aplica'], axis=1)\n",
        "\n",
        "df = df.drop([\n",
        "    'motivo_rechazo_solicitud_No Aplica',\n",
        "    'motivo_rechazo_solicitud_Financiero',\n",
        "    'motivo_rechazo_solicitud_Errores en la Solicitud'\n",
        "], axis=1)\n",
        "\n",
        "# df = df.drop([\n",
        "#     'motivo_rechazo_solicitud_Financiero',\n",
        "#     'motivo_rechazo_solicitud_Errores en la Solicitud',\n",
        "#     'motivo_rechazo_solicitud_Tiempos y Procesos',\n",
        "#     'motivo_rechazo_solicitud_Otro',\n",
        "#     'motivo_rechazo_solicitud_Falta de Interés',\n",
        "#     'motivo_rechazo_solicitud_Doble Solicitud'\n",
        "# ], axis=1)\n",
        "\n",
        "# Mostrar el DataFrame después de eliminar las columnas\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIEJvOkF7RKV"
      },
      "outputs": [],
      "source": [
        "# Calcular la matriz de correlación\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Visualizar la matriz de correlación\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Matriz de Correlación\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqTm8wuH7RKW"
      },
      "source": [
        "## **División de los Datos**  \n",
        "\n",
        "Este paso es importante porque nos permite evaluar qué tan bien se desempeña el modelo con datos no vistos, simulando el comportamiento en el mundo real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVglTlGx7RKW"
      },
      "outputs": [],
      "source": [
        "# Definir la variable objetivo (Y) y las variables predictoras (X)\n",
        "X = df.drop(columns=['venta'])  # Eliminamos la variable objetivo del conjunto de predictores\n",
        "y = df['venta']  # Variable objetivo\n",
        "\n",
        "# Verificar las dimensiones de los conjuntos de datos\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDjJDH7o7RKW"
      },
      "outputs": [],
      "source": [
        "#format the features names:\n",
        "X.index.names = ['Customer_ID']\n",
        "X.columns = [col.replace(' ', '_') for col in X.columns.tolist()]\n",
        "X.columns = [col.replace('(', '_') for col in X.columns.tolist()]\n",
        "X.columns = [col.replace(')', '') for col in X.columns.tolist()]\n",
        "X.columns = [col.replace(']', '_') for col in X.columns.tolist()]\n",
        "X.columns = [col.replace(',', '') for col in X.columns.tolist()]\n",
        "\n",
        "X.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we8rIUn67RKW"
      },
      "outputs": [],
      "source": [
        "\n",
        "# using the train test split function\n",
        "# Dividir el dataset en conjunto de entrenamiento (80%) y prueba (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Verificar el tamaño de los conjuntos resultantes\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XC-uroC7RKW"
      },
      "source": [
        "## **Estandarizar los datos**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spHzg4OF7RKW"
      },
      "outputs": [],
      "source": [
        "# Estandarizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_y67j7i7RKW"
      },
      "source": [
        "***\n",
        "## **Predecir si habrá venta o no (venta)**\n",
        "\n",
        "## **Modelo de Regresión Logística**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQmalylp7RKW"
      },
      "outputs": [],
      "source": [
        "# Entrenar un modelo de Regresión Logística\n",
        "log_reg2 = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_reg2.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predicciones en el conjunto de prueba\n",
        "y_pred = log_reg2.predict(X_test_scaled)\n",
        "\n",
        "# Medir el accuracy\n",
        "accuracy2 = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "conf_matrix2 = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calcular el reporte de clasificación\n",
        "class_report2 = classification_report(y_test, y_pred)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(f\"Accuracy: {accuracy2}\")\n",
        "# print(\"Confusion Matrix:\")\n",
        "# print(conf_matrix2)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report2)\n",
        "\n",
        "# Crear un heatmap para la matriz de confusión\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(conf_matrix2, annot=True, fmt='d', cmap='Blues', xticklabels=['Clase 0', 'Clase 1'], yticklabels=['Clase 0', 'Clase 1'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHrecnMX7RKX"
      },
      "source": [
        "### Modelo Aplicado: Regresión Logística\n",
        "\n",
        "- ¿Por qué usar Regresión Logística?\n",
        "La Regresión Logística es un modelo adecuado porque: Es ideal para problemas de clasificación binaria (venta = 1 o venta = 0).\n",
        "\n",
        "- Accuracy del modelo: 81.1%\n",
        "- Weighted F1-Score: 79%\n",
        "\n",
        "> Matriz de Confusión\n",
        "\n",
        "- 1540 casos correctamente clasificados como \"Venta\" (Clase 1)\n",
        "- 386 casos correctamente clasificados como \"No Venta\" (Clase 0)\n",
        "- 448 falsos positivos (predijo \"Venta\" pero no ocurrió).\n",
        "- 0 falsos negativos (ninguna venta real se clasificó erróneamente como \"No Venta\").\n",
        "\n",
        "> Consideraciones\n",
        "\n",
        "- El modelo logra una alta precisión en identificar clientes que sí compran (Recall = 1.00 en Clase 1).\n",
        "- Problema con la Clase 0 (No Venta): La precisión es baja, indicando que el modelo predice muchas ventas que realmente no ocurren.\n",
        "- Posible mejora: Se puede probar con otro modelo como Árboles de Decisión o Random Forest para mejorar la predicción de clientes que no compran."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dy9YnbO07RKX"
      },
      "outputs": [],
      "source": [
        "common_rows = X_train.merge(X_test, how='inner')\n",
        "print(f\"Número de filas compartidas entre train y test: {common_rows.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zHekKsw7RKX"
      },
      "outputs": [],
      "source": [
        "y_probs = log_reg2.predict_proba(X_test_scaled)[:, 1]\n",
        "plt.hist(y_probs, bins=20)\n",
        "plt.title(\"Distribución de Probabilidades de Predicción\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_ovClUt7RKX"
      },
      "source": [
        "> Se observan dos grupos bien diferenciados:\n",
        "- Un grupo con probabilidades cercanas a 0.0, lo que indica predicciones seguras de \"No Venta\".\n",
        "- Otro grupo con probabilidades entre 0.6 y 0.9, indicando predicciones altas de \"Venta\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTlryV2h7RKX"
      },
      "source": [
        "## Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUnXzNAw7RKX"
      },
      "outputs": [],
      "source": [
        "# Aplicar Lasso\n",
        "lasso = Lasso(alpha=0.05)\n",
        "lasso.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Obtener las características seleccionadas\n",
        "coefficients = lasso.coef_\n",
        "selected_features = X_train.columns[coefficients != 0]\n",
        "print(\"Características seleccionadas:\", selected_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXmU6eDY7RKX"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QltljYHu7RKY"
      },
      "outputs": [],
      "source": [
        "# Entrenar un modelo Random Forest\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Obtener la importancia de las características\n",
        "feature_importances = model.feature_importances_\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# Crear un DataFrame con la importancia de las características\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Mostrar las características más importantes\n",
        "print(importance_df)\n",
        "\n",
        "# Seleccionar las características más relevantes (por ejemplo, las top 10)\n",
        "selected_features = importance_df['Feature'].head(10).tolist()\n",
        "print(\"Características seleccionadas:\", selected_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yQKHID17RKY"
      },
      "source": [
        "### Random Forest (Basado en Árboles)\n",
        "\n",
        "- Random Forest es un modelo no lineal que no necesita normalización y maneja bien interacciones y relaciones no lineales.\n",
        "- Importancia de características: Mide cuánto cada variable mejora la predicción en promedio (por reducción de impureza o permutaciones).\n",
        "- Puede seleccionar muchas variables, incluso si están correlacionadas.\n",
        "- Por eso seleccionó varias características, porque identifica relaciones complejas entre las variables y la variable objetivo (venta).\n",
        "\n",
        "### Lasso (Regresión Lineal con Regularización L1)\n",
        "\n",
        "- Lasso fuerza muchos coeficientes a ser exactamente 0 si la variable no tiene suficiente impacto en la predicción.\n",
        "- Es un modelo lineal, lo que significa que solo capta relaciones lineales entre las variables y la variable objetivo.\n",
        "- Si las variables están muy correlacionadas, Lasso tiende a seleccionar solo una de ellas o ninguna.\n",
        "- Si las variables tienen coeficientes pequeños, un alpha muy grande en Lasso puede hacer que todas queden en 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLTWcYoj7RKY"
      },
      "source": [
        "## **Modelo Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yqmdtxN7RKY"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)  # Aquí el modelo aprende a predecir 'venta' basado en las características de X_train\n",
        "\n",
        "# Hacer predicciones\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluar la precisión del modelo\n",
        "# Medir el accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calcular el reporte de clasificación\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "#print(\"Confusion Matrix:\")\n",
        "#print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "# Crear un heatmap para la matriz de confusión\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Clase 0', 'Clase 1'], yticklabels=['Clase 0', 'Clase 1'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSueAjog7RKZ"
      },
      "source": [
        "***\n",
        "***\n",
        "## **Predecir el precio del plan en función del estrato (price_plan)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUhb4Hvb7RKZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twvr2a9f7RKZ"
      },
      "outputs": [],
      "source": [
        "# Definir la variable objetivo (Y) y las variables predictoras (X)\n",
        "X_reg = df.drop(columns=['price_plan'])  # Eliminamos la variable objetivo del conjunto de predictores\n",
        "y_reg = df['price_plan']  # Variable objetivo\n",
        "\n",
        "# Dividir el dataset en conjunto de entrenamiento (80%) y prueba (20%)\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrenar un modelo de Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_regressor.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "# Predicciones en el conjunto de prueba\n",
        "y_pred_reg = rf_regressor.predict(X_test_reg)\n",
        "\n",
        "# Evaluar el modelo\n",
        "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
        "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test_reg, y_pred_reg)\n",
        "\n",
        "# Mostrar resultados\n",
        "print('MAE:', mae)\n",
        "print('MSE:', mse)\n",
        "print('RMSE:', rmse)\n",
        "print('R2:', r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAd92QsM7RKZ"
      },
      "source": [
        "MAE (Error Absoluto Medio): 889.08\n",
        "- En promedio, el modelo se equivoca por ~813 unidades monetarias al predecir el precio del plan.\n",
        "- El error absoluto medio (~813) indica que en la mayoría de los casos, la predicción del precio estará dentro de un margen aceptable.\n",
        "\n",
        "MSE (Error Cuadrático Medio): 3,778,795.64\n",
        "- Indica la variabilidad de los errores (los valores grandes son comunes en MSE).\n",
        "\n",
        "RMSE (Raíz del Error Cuadrático Medio): 1943.91\n",
        "- Un error promedio de ~1944 unidades.\n",
        "\n",
        "R² (Coeficiente de Determinación): 0.91\n",
        "- El modelo explica el 91% de la variabilidad en price_plan, lo cual es bastante bueno.\n",
        "- Un R² de 0.91 indica que el modelo es muy bueno para predecir price_plan en función de las variables disponibles.\n",
        "\n",
        "\n",
        "Sin embargo, si el precio del plan varía en rangos pequeños, este error puede ser significativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmu_k1JH7RKZ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./Data/data_codificada.csv\")\n",
        "# Eliminar duplicados y mantener solo la primera aparición\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "df = df.drop([\n",
        "    'motivo_rechazo_solicitud_No Aplica',\n",
        "    'motivo_rechazo_solicitud_Financiero',\n",
        "    'motivo_rechazo_solicitud_Errores en la Solicitud'\n",
        "], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIvBVOFO7RKa"
      },
      "outputs": [],
      "source": [
        "# Usar solo el estrato como predictor\n",
        "X_reg = df[['estrato']]\n",
        "y_reg = df['price_plan']\n",
        "\n",
        "# Dividir el dataset en conjunto de entrenamiento (80%) y prueba (20%)\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrenar un modelo de Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_regressor.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "# Predecir solo para los valores únicos de estrato\n",
        "estrato_unicos = X_reg['estrato'].unique()\n",
        "estrato_unicos = sorted(estrato_unicos)  # Ordenar los valores únicos\n",
        "\n",
        "# Crear un dataframe con los valores únicos de estrato\n",
        "df_pred = pd.DataFrame({'estrato': estrato_unicos})\n",
        "df_pred['price_plan_predicted'] = rf_regressor.predict(df_pred)\n",
        "print(df_pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0d1ZfZA7RKa"
      },
      "source": [
        "### Predicción del Precio del Plan en función del Estrato\n",
        "\n",
        "> Interpretación:\n",
        "- Tendencia esperada: A medida que aumenta el estrato, el precio del plan también aumenta.\n",
        "- Predicciones alineadas: El modelo predice valores dentro del rango de cada estrato.\n",
        "- Variabilidad dentro de cada estrato: Algunos estratos tienen planes con precios más variados."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "django_2_0",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}